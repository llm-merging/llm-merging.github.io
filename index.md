---
layout: default
---

## See you in Vancouver!

See you in West Meeting Room 210, Sun 15 Dec noon EST â€” 2:50 p.m. EST. Check our [NeurIPS 2024 schedule](https://neurips.cc/virtual/2024/competition/84794#wse-detail-109333)!

Our accepted technical reports are at <a href="https://openreview.net/group?id=NeurIPS.cc/2024/Competition/LMC#tab-accept-oral">OpenReview page of LLM Merging Compeition NeurIPS 2024</a>

# Announcing Competition Winners

## Performance Track

| Placement    | Winner                                             |
|--------------|----------------------------------------------------|
| 1st Place    | [QiangGao, Jisheng fang, Hao Mo](https://openreview.net/forum?id=zcnDi0i23y)                                  |
| 2nd Place    | [Yinuo Zhang](https://openreview.net/forum?id=VndTgXbAgz)                                   |
| 3rd Place    | [Zixiang Di, Yaoming Yang, Mei Jiang, Bingdong Li, Hong Qian, Aimin Zhou](https://openreview.net/forum?id=Xl8uuaNj1X)                                    |

## Efficiency Track

| Winner           |
|------------------|
| [Yizhen Zhang, Yang Ding, Jie Wu, Yujiu Yang](https://openreview.net/forum?id=rJ1miae6PJ)   |

## Most Creative Paper Write-up Track

| Winner                      |
|-----------------------------|
| [Siddharth Gupta, Aakash Gupta](https://openreview.net/forum?id=4VD2jMqJbN)        |



Join our discord <a href="https://discord.com/invite/VYfFexfSpZ">here</a> !

## Aims and Focus
<p style='text-align: justify;'>
Training high-performing large language models (LLMs) from scratch is a notoriously expensive and difficult task, costing hundreds of millions of dollars in compute alone. These pretrained LLMs, however, can cheaply and easily be adapted to new tasks via fine-tuning, leading to a proliferation of models that suit specific use cases. Recent work has shown that specialized fine-tuned models can be rapidly **merged** to combine capabilities and generalize to new skills. 
</p>

## Get started

The competition allows any current model that follows the general conditions (e.g., existed when the competition was announced and is up to 8Gb) see Rules for explicit conditions.


<p style='text-align: justify;'>
A starter kit with an end-to-end submission flow can be found here:<br>

[https://github.com/llm-merging/LLM-Merging](https://github.com/llm-merging/LLM-Merging)
</p>

- Please submit a report describing your merging method to our [OpenReview LMC 2024](https://openreview.net/group?id=NeurIPS.cc/2024/Competition/LMC) page. Please follow the standard NeurIPS format [template](https://www.overleaf.com/latex/templates/neurips-2024/tpsbbrdqcmsh). There are no strict restrictions or limitations for the report, but we suggest that the page limit not exceed 4 pages. All submitted reports will be publicly accessible on our website.

<p>For more details, please check the <a href="challenge.html">Challenge</a>, <a href="rules.html">Rules</a>, and <a href="starter_kit.html">Starter Kit</a> tab.</p>

## Important Dates

<table class="foo">
    <tr>
        <td width="50%"><b>Submission Open</b></td>
        <td width="50%"> <s>Early June, 2024</s> </td>
    </tr>
    <tr>
        <td width="50%"><b>Code Submission Deadline</b></td>
        <td width="50%"> <s>September 13th, 2024</s>, New! October 11th, 2024</td>
    </tr>
    <tr>
        <td width="50%"><b>Report Submission Deadline</b></td>
        <td width="50%"> <s>November 1st, 2024</s> </td>
    </tr>
    <tr>
        <td width="50%"><b>Winners Notification</b></td>
        <td width="50%"> <s>Mid-November, 2024 </s> </td>
    </tr>
    <tr>
        <td width="50%"><b>Competition Presentation</b></td>
        <td width="50%"> <s>December 15th, 2024</s> </td>
    </tr>
</table>
* Currently the deadline is October 11th, 2024. Please check our website and the announcements in the Discord channel for updates.*

<!-- <br>

This raises the question: given a new suite of desired skills and design parameters, is it necessary to fine-tune or train yet another LLM from scratch, or can similar existing models be re-purposed for a new task with the right selection or merging procedure? 

<br>

<p style='text-align: justify;'>

The LLM Merging challenge aims to spur the development and evaluation of methods for merging and reusing existing models to form stronger new models without needing additional training. Specifically, the competition focuses on merging existing publicly-released expert models from Huggingface, using only minimal compute and additional parameters. The goal will be to develop merged models that outperform existing models and existing merging baselines. Submissions will be judged based on the average accuracy on a set of held-out multiple-choice evaluation tasks. 
To make the competition as accessible as possible and ensure that the merging procedures are more efficient than fine-tuning, we will enforce a compute budget and focus on merging models with fewer than 8B parameters. A starter kit with all necessary materials (baseline implementations, requirements, the evaluation script, etc.) will be released on May 1st. 
</p> -->


<!-- ## Organizing Institutions

<table cellspacing="0" cellpadding="0" style="border-collapse: collapse;">
    <tr>
        <td style="text-align: center; border: none;"><img src="assets/fig/hf-logo-with-title.png" width="300"></td>
        <td style="border: none;"><img src="assets/fig/sakana_logo.png" width="250"></td>
        <td style="border: none;"><img src="assets/fig/arceeai_transparent background.svg" width="300"></td>
    </tr>

</table> -->


## Sponsors

<table cellspacing="0" cellpadding="0" style="border-collapse: collapse;">
    <tr>
        <td style="text-align: center; border: none;"><img src="assets/fig/hf-logo-with-title.png" width="300"></td>
        <td style="border: none;"><img src="assets/fig/sakana_logo.png" width="250"></td>
        <td style="border: none;"><img src="assets/fig/arceeai_transparent background.svg" width="300"></td>
    </tr>
    <!-- <tr>
                <td style="border: none;"><img src="https://github.com/llm-efficiency-challenge/llm-efficiency-challenge.github.io/assets/3282513/7185238e-b21c-4d82-91f3-86d3465523db" width="300"></td>
        <td style="border: none;"><img src="https://github.com/llm-efficiency-challenge/llm-efficiency-challenge.github.io/assets/3282513/c227bd00-a396-49a5-928c-1d40482508a8" width="300"></td>
        <td style="border: none;"></td>
    </tr> -->
</table>
